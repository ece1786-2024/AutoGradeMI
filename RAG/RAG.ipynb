{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from datasets import DatasetDict, load_dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "import faiss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['prompt', 'essay', 'label'],\n",
      "        num_rows: 9766\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "dataset = load_dataset('csv', data_files='..\\data\\dataset\\processed\\clean_data_gpt2.csv')\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "split the train and test part for 9:1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['prompt', 'essay', 'label'],\n",
      "        num_rows: 8789\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['prompt', 'essay', 'label'],\n",
      "        num_rows: 977\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "split_dataset = dataset['train'].train_test_split(test_size=0.1, seed=42)\n",
    "print(split_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, start to create embedding database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_embedding(text, model=\"text-embedding-ada-002\"):\n",
    "    try:\n",
    "        response = client.embeddings.create(input=text, model=model)\n",
    "        return response.data[0].embedding\n",
    "    except Exception as e:\n",
    "        print(f\"Error generating embedding\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_embeddings_batch(texts, model=\"text-embedding-ada-002\"):\n",
    "    try:\n",
    "        response = client.embeddings.create(input=texts, model=model)\n",
    "        return [item.embedding for item in response.data]\n",
    "    except Exception as e:\n",
    "        print(f\"Error generating embeddings for batch: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating embeddings: 100%|██████████| 88/88 [03:27<00:00,  2.35s/it]\n"
     ]
    }
   ],
   "source": [
    "embeddings = []\n",
    "metadata = []\n",
    "\n",
    "\n",
    "batch_size = 100  \n",
    "\n",
    "for i in tqdm(range(0, len(split_dataset['train']), batch_size), desc=\"Generating embeddings\"):\n",
    "    batch_samples = split_dataset['train'][i:i+batch_size]\n",
    "\n",
    "    \n",
    "    \n",
    "    combined_texts = [\n",
    "        f\"Prompt: {prompt}\\nEssay: {essay}\"\n",
    "        for prompt, essay in zip(batch_samples['prompt'], batch_samples['essay'])\n",
    "    ]\n",
    "    \n",
    "    batch_embeddings = generate_embeddings_batch(combined_texts)\n",
    "    if batch_embeddings is not None:\n",
    "        embeddings.extend(batch_embeddings)\n",
    "        metadata.extend([\n",
    "            {\"prompt\": prompt, \"essay\": essay, \"label\": label}\n",
    "            for prompt, essay, label in zip(\n",
    "                batch_samples['prompt'], batch_samples['essay'], batch_samples['label']\n",
    "            )\n",
    "        ])\n",
    "    \n",
    "\n",
    "# save the embeddings\n",
    "\n",
    "embeddings_np = np.array(embeddings, dtype=np.float32)\n",
    "faiss.normalize_L2(embeddings_np)  \n",
    "\n",
    "dimension = len(embeddings_np[0])  \n",
    "index = faiss.IndexFlatIP(dimension)  \n",
    "index.add(embeddings_np)  \n",
    "\n",
    "# save the reults\n",
    "faiss.write_index(index, \"faiss_index_train.bin\")\n",
    "\n",
    "\n",
    "with open(\"embeddings_dataset_train.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(metadata, f, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RAG using topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating embeddings: 100%|██████████| 88/88 [01:06<00:00,  1.33it/s]\n"
     ]
    }
   ],
   "source": [
    "embeddings = []\n",
    "metadata = []\n",
    "\n",
    "\n",
    "batch_size = 100  \n",
    "\n",
    "for i in tqdm(range(0, len(split_dataset['train']), batch_size), desc=\"Generating embeddings\"):\n",
    "    batch_samples = split_dataset['train'][i:i+batch_size]\n",
    "\n",
    "    \n",
    "    \n",
    "    topics = [\n",
    "        f\"{prompt}\"\n",
    "        for prompt in batch_samples['prompt']\n",
    "    ]\n",
    "    \n",
    "    batch_embeddings = generate_embeddings_batch(topics)\n",
    "    if batch_embeddings is not None:\n",
    "        embeddings.extend(batch_embeddings)\n",
    "        metadata.extend([\n",
    "            {\"prompt\": prompt, \"essay\": essay, \"label\": label}\n",
    "            for prompt, essay, label in zip(\n",
    "                batch_samples['prompt'], batch_samples['essay'], batch_samples['label']\n",
    "            )\n",
    "        ])\n",
    "    \n",
    "\n",
    "# save the embeddings\n",
    "\n",
    "embeddings_np = np.array(embeddings, dtype=np.float32)\n",
    "faiss.normalize_L2(embeddings_np)  \n",
    "\n",
    "dimension = len(embeddings_np[0])  \n",
    "index = faiss.IndexFlatIP(dimension)  \n",
    "index.add(embeddings_np)  \n",
    "\n",
    "# save the reults\n",
    "faiss.write_index(index, \"faiss_index_train_topics.bin\")\n",
    "\n",
    "\n",
    "with open(\"embeddings_dataset_train_topics.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(metadata, f, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "using test samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating embeddings: 100%|██████████| 10/10 [00:08<00:00,  1.15it/s]\n"
     ]
    }
   ],
   "source": [
    "embeddings = []\n",
    "metadata = []\n",
    "\n",
    "\n",
    "batch_size = 100  \n",
    "\n",
    "for i in tqdm(range(0, len(split_dataset['test']), batch_size), desc=\"Generating embeddings\"):\n",
    "    batch_samples = split_dataset['test'][i:i+batch_size]\n",
    "\n",
    "    \n",
    "    \n",
    "    topics = [\n",
    "        f\"{prompt}\"\n",
    "        for prompt in batch_samples['prompt']\n",
    "    ]\n",
    "    \n",
    "    batch_embeddings = generate_embeddings_batch(topics)\n",
    "    if batch_embeddings is not None:\n",
    "        embeddings.extend(batch_embeddings)\n",
    "        metadata.extend([\n",
    "            {\"prompt\": prompt, \"essay\": essay, \"label\": label}\n",
    "            for prompt, essay, label in zip(\n",
    "                batch_samples['prompt'], batch_samples['essay'], batch_samples['label']\n",
    "            )\n",
    "        ])\n",
    "    \n",
    "\n",
    "# save the embeddings\n",
    "\n",
    "embeddings_np = np.array(embeddings, dtype=np.float32)\n",
    "faiss.normalize_L2(embeddings_np)  \n",
    "\n",
    "dimension = len(embeddings_np[0])  \n",
    "index = faiss.IndexFlatIP(dimension)  \n",
    "index.add(embeddings_np)  \n",
    "\n",
    "# save the reults\n",
    "faiss.write_index(index, \"faiss_index_test_topics.bin\")\n",
    "\n",
    "\n",
    "with open(\"embeddings_dataset_test_topics.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(metadata, f, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result 1:\n",
      "  Prompt: Many people use social media to keep in touch with other people and for news events. Do the advantages of this outweigh the disadvantages?\n",
      "  Essay: In this day and age, the majority of people use social media to connect with each other and to receive  news. In my opinion, the benefits of using social platforms such as better communication and easy accessibility to news override the drawbacks of distractions and getting misleading information.\n",
      "\n",
      "On the one hand, a large number of people use social networks to communicate with one another such as by using What's App or Facebook. This is a much easier and convenient way of having conversations with family members or friends especially when they are living in different cities or countries. For instance, international students can talk to their parents or siblings whenever they want through What's app video calls. Hence, it is extremely beneficial for those who live far away from their loved ones.\n",
      "\n",
      "Furthermore, regarding the news headlines, social platform plays an important role in terms of getting updates. Nowadays, it is not necessary to wait for the newspaper to get  information about what is going on around the globe. As we have online news channels, people can watch the latest stories whenever they want. Thus, the social network helps in keeping people aware of their surroundings every second.\n",
      "\n",
      "On the other hand, usage of social media can also have negative impacts such as distraction or wastage of time. Many young people spend extended hours on their mobiles either talking to their peers or chatting in  groups for time pass. Hence, it is highly unproductive for them. Moreover, getting online news can sometimes be misguiding as people can share fake news to gain popularity and it also becomes difficult to distinguish between true and false information. Therefore, the use of social websites can have detrimental effects.\n",
      "\n",
      "To conclude, social media is a great medium for connecting with people and receiving headlines for many people. In my opinion, the pros of using these online websites such as better communication and easy access to news updates are far better than the cons which include distractability and fake news stories.\n",
      "  Label: 5\n",
      "  Similarity: 0.9954712390899658\n",
      "\n",
      "Result 2:\n",
      "  Prompt: Many people use social media to keep in touch with other people and for news events. Do the advantages of this outweigh the disadvantages?\n",
      "  Essay: Nowadays, using social applications in order to communicate better and update report events becomes widespread among people. This essay will argue that the advantages of this outweigh the drawback. I will first demonstrate that the facilitated relationship and immediate announcement update are the benefits, followed by an analysis of how the primary disadvantage, namely time-consuming, is not valid. \n",
      "\n",
      "Firstly, public applications are made in order to improve communications among people. Hence, connections are made effortlessly regardless of the location and therefore the well-being in the society enhances. If an individual wants to talk to a friend, who lives in a different country he/she just need to press a click. It has been proved that parents whose children live abroad are delighted to monitor their children's pictures on  Instagram. In addition, because of technological advancements in apps, various information is spread in a second and therefore anyone can access  a variety of broadcasts. Furthermore, reporters could upload their data to these platforms where ever they are. For example, different reports from Olympic events were reported while games were performed. \n",
      "\n",
      "On the other hand, those opposed to this say that each person would waste a lot of time on these social websites. However, there is actually no evidence to support this view and public platforms would help nations regarding their relationship and information. For instance, my boss checked his Instagram account and informed us about important data while he performed excellently in his job. \n",
      "\n",
      "To summarize, the fact that social media mitigates communications and accelerates news spreading clearly outweighs the flawed that it wastes moments.\n",
      "  Label: 8\n",
      "  Similarity: 0.9954712390899658\n",
      "\n",
      "Result 3:\n",
      "  Prompt: Many people use social media to keep in touch with other people and for news events. Do the advantages of this outweigh the disadvantages?\n",
      "  Essay: In the modern era, the masses are frequently using social media platforms like Instagram, Facebook and YouTube to contact other folks and to keep themselves updated about current affairs around the world. I believe the pros of this phenomenon will outbalance the cons, as we will see in this essay.\n",
      "\n",
      "To begin with, the tendency of making use of social media these days has many advantages for people dwelling on different continents. With aid of these online websites and ,applications one can confabulate with their loved ones residing in some corner of this gigantic world. Now, the public can stay in touch with their families and friends with the snap of their fingers. This idea has lessened the communication barriers and was considered a dream of the past which has now become a stark reality owing to the advancement in science and technology. For instance, people living in an underdeveloped country in Africa like Kenya can talk to their peers living in Canada in North America. Moreover, people who are curious about the current happenings around the globe can get to know news with the effective use of data and information available on the internet. This enhances their knowledge and intellectual development. Likewise, this can also help them to adapt to the fastly transforming world. Hence, social media proves to be beneficial for folks.\n",
      "\n",
      "On the contrary, along with a plethora of vantages, social media has notable disadvantages as well. One of the most considerable negative aspects is that it engenders feelings of jealousy and envy among people. For example, when folks who are not affluent view their peers and colleagues as living in the lap of luxuries, they tend to develop negative sentiments such as resentment and hatred which are detrimental to their mental health. Furthermore, social media is tremendously corrupting day-to-day human interactions by reducing the number of physical interactions in the everyday lives of the masses. Nowadays, people are more inclined to interact with other people using mobile applications and online websites rather than visiting in person as they used to do in the past. This transmutation in social demeanour has negative implications on the traditions and customs of a particular culture. One can see this with the crowd losing their stranglehold on the ethics and values of society. Therefore, the use of social media possesses considerable and noteworthy cons for folks.\n",
      "\n",
      "To conclude, the usage of the internet has become heavily popular since the dawn of the twenty-first century. The internet is being utilised by the public to check on other folks or to enlighten themselves about news events. The remarkable pros of this trend far outbalance its cons, as were discussed in this essay.\n",
      "  Label: 10\n",
      "  Similarity: 0.9954547882080078\n",
      "\n"
     ]
    }
   ],
   "source": [
    "index = faiss.read_index(\"faiss_index_train_topics.bin\")\n",
    "with open(\"embeddings_dataset_train_topics.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    metadata = json.load(f)\n",
    "\n",
    "\n",
    "def search_cosine_similarity(query_text, top_k=3):\n",
    "    \n",
    "    query_embedding = generate_embedding(query_text)\n",
    "    if query_embedding is None:\n",
    "        return []\n",
    "    \n",
    "    \n",
    "    query_embedding_np = np.array([query_embedding], dtype=np.float32)\n",
    "    faiss.normalize_L2(query_embedding_np)\n",
    "    \n",
    "    \n",
    "    distances, indices = index.search(query_embedding_np, top_k)\n",
    "    \n",
    "    \n",
    "    results = []\n",
    "    for i, idx in enumerate(indices[0]):\n",
    "        result = metadata[idx]\n",
    "        result[\"similarity\"] = distances[0][i]  \n",
    "        results.append(result)\n",
    "    return results\n",
    "\n",
    "\n",
    "query = \"\"\"Many people use social media to keep in touch with other people and for news events. Do the advantages of this outweigh the disadvantages?\n",
    "\"\"\"\n",
    "results = search_cosine_similarity(query, top_k=3)\n",
    "\n",
    "for i, result in enumerate(results):\n",
    "    print(f\"Result {i+1}:\")\n",
    "    print(f\"  Prompt: {result['prompt']}\")\n",
    "    print(f\"  Essay: {result['essay']}\")\n",
    "    print(f\"  Label: {result['label']}\")\n",
    "    print(f\"  Similarity: {result['similarity']}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating embeddings:  15%|█▌        | 1359/8789 [04:35<19:43,  6.28it/s]  "
     ]
    }
   ],
   "source": [
    "# embeddings = []\n",
    "# metadata = []\n",
    "# for sample in tqdm(split_dataset['train'], desc=\"Generating embeddings\"):\n",
    "#     combined_text = f\"Prompt: {sample['prompt']}\\nEssay: {sample['essay']}\"\n",
    "    \n",
    "#     embedding = generate_embedding(combined_text)\n",
    "#     if embedding is not None:\n",
    "#         embeddings.append(embedding)\n",
    "#         metadata.append({\n",
    "#             \"prompt\": sample[\"prompt\"],\n",
    "#             \"essay\": sample[\"essay\"],\n",
    "#             \"label\": sample[\"label\"]\n",
    "#         })\n",
    "\n",
    "                         \n",
    "\n",
    "# # save the embeddings\n",
    "\n",
    "# embeddings_np = np.array(embeddings, dtype=np.float32)\n",
    "# faiss.normalize_L2(embeddings_np)  \n",
    "\n",
    "# dimension = len(embeddings_np[0])  \n",
    "# index = faiss.IndexFlatIP(dimension)  \n",
    "# index.add(embeddings_np)  \n",
    "\n",
    "# # save the reults\n",
    "# faiss.write_index(index, \"faiss_index.bin\")\n",
    "\n",
    "\n",
    "# with open(\"embeddings_dataset.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "#     json.dump(metadata, f, ensure_ascii=False, indent=4)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "130\n",
      "131\n",
      "132\n",
      "133\n",
      "134\n",
      "135\n",
      "136\n",
      "137\n",
      "138\n",
      "139\n",
      "140\n",
      "141\n",
      "142\n",
      "143\n",
      "144\n",
      "145\n",
      "146\n",
      "147\n",
      "148\n",
      "149\n",
      "Accuracy: 0.18666666666666668\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "index = faiss.read_index(\"faiss_index_train.bin\")\n",
    "with open(\"embeddings_dataset_test.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    metadata_test = json.load(f)\n",
    "\n",
    "with open(\"embeddings_dataset_train.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    metadata_train = json.load(f)\n",
    "\n",
    "def search_cosine_similarity(query_text, dataset, top_k=3):\n",
    "    \n",
    "    query_embedding = generate_embedding(query_text)\n",
    "    if query_embedding is None:\n",
    "        return []\n",
    "    \n",
    "    \n",
    "    query_embedding_np = np.array([query_embedding], dtype=np.float32)\n",
    "    faiss.normalize_L2(query_embedding_np)\n",
    "    \n",
    "    \n",
    "    distances, indices = index.search(query_embedding_np, top_k)\n",
    "    \n",
    "    \n",
    "    results = []\n",
    "    for i, idx in enumerate(indices[0]):\n",
    "        result = dataset[idx]\n",
    "        result[\"similarity\"] = distances[0][i]  \n",
    "        results.append(result)\n",
    "    return results\n",
    "\n",
    "correct = 0\n",
    "cnt = 0\n",
    "timeout_duration = 10\n",
    "for data in metadata_test:\n",
    "    query = f\"Prompt: {data['prompt']}\\nEssay: {data['essay']}\"\n",
    "    results = search_cosine_similarity(query, metadata_train, top_k=2)\n",
    "\n",
    "    answer = float(data['label'])\n",
    "    curr_score = 0\n",
    "    weight = [0.8, 0.2]\n",
    "    for i, result in enumerate(results):\n",
    "        curr_score += result['label']*weight[i]\n",
    "\n",
    "    # print(curr_score)\n",
    "    print(cnt)\n",
    "\n",
    "\n",
    "    if (abs(answer - curr_score) <= 1):\n",
    "        correct += 1\n",
    "    \n",
    "    cnt += 1\n",
    "    if cnt == 150:\n",
    "        break\n",
    "    # print(\"=====================\")\n",
    "\n",
    "print(f\"Accuracy: {correct/cnt}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RAG with topic_essay combined similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "create embedding database using essay content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating embeddings: 100%|██████████| 88/88 [03:00<00:00,  2.05s/it]\n"
     ]
    }
   ],
   "source": [
    "embeddings = []\n",
    "metadata = []\n",
    "\n",
    "\n",
    "batch_size = 100  \n",
    "\n",
    "for i in tqdm(range(0, len(split_dataset['train']), batch_size), desc=\"Generating embeddings\"):\n",
    "    batch_samples = split_dataset['train'][i:i+batch_size]\n",
    "\n",
    "    \n",
    "    \n",
    "    essay = [\n",
    "        f\"{essay}\"\n",
    "        for essay in batch_samples['essay']\n",
    "    ]\n",
    "    \n",
    "    batch_embeddings = generate_embeddings_batch(essay)\n",
    "    if batch_embeddings is not None:\n",
    "        embeddings.extend(batch_embeddings)\n",
    "        metadata.extend([\n",
    "            {\"prompt\": prompt, \"essay\": essay, \"label\": label}\n",
    "            for prompt, essay, label in zip(\n",
    "                batch_samples['prompt'], batch_samples['essay'], batch_samples['label']\n",
    "            )\n",
    "        ])\n",
    "    \n",
    "\n",
    "# save the embeddings\n",
    "\n",
    "embeddings_np = np.array(embeddings, dtype=np.float32)\n",
    "faiss.normalize_L2(embeddings_np)  \n",
    "\n",
    "dimension = len(embeddings_np[0])  \n",
    "index = faiss.IndexFlatIP(dimension)  \n",
    "index.add(embeddings_np)  \n",
    "\n",
    "# save the reults\n",
    "faiss.write_index(index, \"faiss_index_train_essay.bin\")\n",
    "\n",
    "\n",
    "with open(\"embeddings_dataset_train_essay.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(metadata, f, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = faiss.read_index(\"faiss_index_train_essay.bin\")\n",
    "with open(\"embeddings_dataset_train_essay.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    metadata = json.load(f)\n",
    "\n",
    "\n",
    "def search_cosine_similarity(query_text, top_k=3):\n",
    "    \n",
    "    query_embedding = generate_embedding(query_text)\n",
    "    if query_embedding is None:\n",
    "        return []\n",
    "    \n",
    "    \n",
    "    query_embedding_np = np.array([query_embedding], dtype=np.float32)\n",
    "    faiss.normalize_L2(query_embedding_np)\n",
    "    \n",
    "    \n",
    "    distances, indices = index.search(query_embedding_np, top_k)\n",
    "    \n",
    "    \n",
    "    results = []\n",
    "    for i, idx in enumerate(indices[0]):\n",
    "        result = metadata[idx]\n",
    "        result[\"similarity\"] = distances[0][i]  \n",
    "        results.append(result)\n",
    "    return results\n",
    "\n",
    "\n",
    "query = \"\"\"Many people use social media to keep in touch with other people and for news events. Do the advantages of this outweigh the disadvantages?\n",
    "\"\"\"\n",
    "results = search_cosine_similarity(query, top_k=3)\n",
    "\n",
    "for i, result in enumerate(results):\n",
    "    print(f\"Result {i+1}:\")\n",
    "    print(f\"  Prompt: {result['prompt']}\")\n",
    "    print(f\"  Essay: {result['essay']}\")\n",
    "    print(f\"  Label: {result['label']}\")\n",
    "    print(f\"  Similarity: {result['similarity']}\")\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ece1786",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
